---
title: "Rekomendasi Musik Spotify menggunakan Metode Unsupervised Learning"
author: "Dedy Gusnadi Sianipar"
date: "4/16/2021"
link-citation : true
output:
  html_document:
    theme: flatly
    higlight: zenburn
    toc: true
    toc_float:
      collapsed: true
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,out.width = "100%", echo = FALSE, fig.align = "center"}
knitr::include_graphics("spotify-Header.jpg")

```


# Pendahuluan
##           {.tabset .tabset-fade .tabset-pills}

### Latar Belakang
  Spotify adalah layanan music digital yang menyediakan akses untuk jutaan lagu dari berbagai artis di dunia. Oleh karena tersedia banyak lagu yang dapat diakses , dapat membuat kita binggung dalam memilih lagu yang ingin kita dengar.

Artikel ini akan membantu anda dalam mengcluster lagu-lagu sehingga dapat membantu pembaca dalam memilih lagu yang sesuai dengan kriteria yang kita inginkan

### Data

Dekripsi Data : 

Akustik: Apakah trek akustik (Nilai lebih tinggi trek akustik)

Danceability: Seberapa cocok lagu untuk berbasis menari (Nilai yang lebih tinggi adalah yang paling bisa menari)

Energi: Mewakili ukuran persepsi dari intensitas dan aktivitas (Musik death metal memiliki energi tinggi)

instrumentalness: Apakah sebuah lagu tidak mengandung vokal (Nilai yang lebih tinggi dari lagu tersebut adalah instrumental)

Kehidupan: Kehadiran penonton dalam rekaman (Lagu dibawakan secara langsung)

Kenyaringan: Tingkat kenyaringan keseluruhan trek dalam desibel (dB)

Kemampuan Berbicara: Kehadiran kata-kata yang diucapkan dalam sebuah trek (Trek mungkin berisi musik atau ucapan)

Valensi: Musik positif yang disampaikan oleh sebuah lagu (Lagu dengan valensi tinggi artinya bahagia atau ceria)

The data I get from Kaggle with this following link:

<p><a href = "https://www.kaggle.com/zaheenhamidani/ultimate-spotify-tracks-db"> Kaggle </a></p>

# Persiapan
##           {.tabset .tabset-fade .tabset-pills}
### Package & Import Data

```{r,message=FALSE}
library(tidyverse)
library(FactoMineR)
library(factoextra)
```

```{r}
data_spotify <- read.csv("SpotifyFeatures.csv")
```

### Lagu Populer

```{r}
popular_song <- data_spotify %>% filter(popularity >= 75)
```

Pemilihan angka 75 merupakan Subjektif, jadi bisa disesuai dengan angka yang teman-teman inginkan

### Filter

Memilih variabel yang digunakan dengan tipe numerik / angka

```{r}
data_clean <- popular_song %>% 
 select(c(acousticness,danceability,energy,instrumentalness,liveness,loudness,speechiness,valence))

head(data_clean)
```
# Exploratory Data Analysis
##           {.tabset .tabset-fade .tabset-pills}
### Check Data

```{r}
glimpse(data_clean)
```
```{r}
anyNA(data_clean)
```
Mantap!, Tidak ada data yang kosong.


```{r}
summary(data_clean)
```
```{r}
as.data.frame(var(data_clean))
plot(prcomp(data_clean))
```

Setelah nilai cek dan varians plot, kita dapat melihat rata-rata semua variabel adalah selisih dan variabel data varians kenyaringan memiliki sangat tinggi dibandingkan variabel lainnya.

Data dengan variabel perbedaan skala tinggi kurang baik untuk analisis clustering karena bersifat bias. Variabel akan dipertimbangkan untuk menangkap varian tertinggi dan variabel lain akan mempertimbangkan untuk tidak memberikan informasi.

Oleh karena itu, kita harus melakukan penskalaan sebelum melakukan clustering.

### Scale
```{r}
data_scale <- data_clean %>% scale() %>% as.data.frame()
```
```{r}
summary(data_scale)
```

```{r}
var(data_scale)
plot(prcomp(data_scale))
```
Mantap!. Data siap diolah


# PCA (Principal Component Analysis)
Fungsi Principal Component Analysis (PCA) adalah untuk mereduksi dimensi data tetapi tetap menyimpan informasi awal, dengan membuat sumbu baru yang dapat menangkap informasi sebanyak mungkin. Sumbu yang dibuat disebut Komponen Utama (PC), di mana sebagian besar informasi ditangkap oleh PC1, diikuti oleh PC2, PC3, PC4, dll

## Membuat PCA
```{r}
data_pca <- PCA(data_scale,scale.unit = F, graph = F)
```

## Visualisasi
```{r}
plot.PCA(data_pca,
         choix = "ind",
         select = "contrib 5",
         habillage = 1)
```
Dari plot yang diperlihatkan kita bisa melihat data outlier 477 , 1557 , 1582 , 2438 , 493

### Variable Factor Map

Untuk melihat kontribusi variabel daru setiap pc, dan meilihat koerlasi antara variable
```{r}
plot.PCA(data_pca, choix = "var")
```
```{r,warning=FALSE}
fviz_contrib(X = data_pca,
             choice = "var",
             axes = 1)
```
```{r}
fviz_contrib(X = data_pca,
             choice = "var",
             axes = 2)
```
Dari plot di atas, kita mendapatkan wawasan:

Dua variabel yang paling diringkas oleh PC1: energi & kenyaringan

Dua variabel yang paling diringkas oleh PC2: kemampuan menari & ucapan

Variabel dengan korelasi positif tinggi:

energi & kenyaringan

kemampuan menari & berbicara

Variabel dengan korelasi negatif tinggi:

energi & ucapan

kemampuan menari & kehidupan


# Clulster / Pengelompokan
##           {.tabset .tabset-fade .tabset-pills}
### Mencari Nilai K Optimum

Sebelum kita melakukan analisis cluster, terlebih dahulu kita perlu menentukan jumlah cluster yang optimal. Dalam metode clustering, kami berusaha untuk meminimalkan jumlah kuadrat dalam cluster (artinya jarak antara observasi dalam cluster yang sama minimal). Untuk mendapatkan jumlah cluster yang optimal dapat digunakan 3 metode yaitu metode elbow, metode siluet, dan statistik gap. Tetapi disini kita akan menggunakan metode elbow

Memilih jumlah cluster menggunakan metode elbow adalah sewenang-wenang. Aturan praktisnya adalah kita memilih jumlah cluster di area “tikungan siku”, dimana grafik jumlah dalam jumlah kotak mulai stagnan dengan bertambahnya jumlah cluster.

```{r, error=FALSE,warning=FALSE}
RNGkind(sample.kind = "Rounding")
set.seed(417)
fviz_nbclust(data_scale, kmeans, method = "wss")
```
Dengan metode elbow, diketahui bahwa 8 cluster sudah cukup baik karena tidak ada penurunan yang signifikan dalam jumlah kotak dalam cluster pada jumlah cluster yang lebih banyak. 



### K-Mean Clustering
Berikut algoritma di balik K-Means Clustering:

Tetapkan nomor secara acak, dari 1 hingga K, untuk setiap pengamatan. Ini berfungsi sebagai tugas cluster awal untuk observasi.
Iteratre sampai tugas cluster berhenti berubah. Untuk setiap cluster K, hitung pusat cluster. Centroid cluster K adalah vektor sarana fitur p untuk pengamatan pada cluster k. Tetapkan setiap observasi ke cluster yang sentroidnya paling dekat (menggunakan jarak euclidean atau pengukuran jarak lainnya)


```{r,warning=FALSE}
RNGkind(sample.kind = "Rounding")
set.seed(417)

# k-means clustering
data_clust <- kmeans(data_clean, centers = 8)
```

### Goodness of Fit
Hasil pengelompokan dapat dilihat dari 3 nilai
Within Sum of Squares ($ withinss): jumlah jarak kuadrat dari setiap observasi ke centroid dari setiap cluster.
Between Sum of Squares ($ betweenss): jumlah jarak kuadrat dari setiap sentroid ke rata-rata global. Berdasarkan jumlah observasi di cluster.
Total Jumlah Kuadrat ($ tots): jumlah kuadrat jarak dari setiap pengamatan ke rata-rata global.

```{r}
data_clust$withinss
```

```{r}
data_clust$betweenss
```
```{r}
data_clust$totss
```
check ration clustering
```{r}
((data_clust$betweenss)/ (data_clust$totss))*100
```

```{r}
fviz_cluster(object=data_clust,
             data = data_clean,
             labelsize = 7)
```

```{r,include=TRUE}
popular_song$cluster <- data_clust$cluster

popular_song %>% 
  select(cluster, acousticness, danceability, energy, instrumentalness, liveness, loudness, speechiness, valence) %>% 
  group_by(cluster) %>% 
  summarise_all(mean)
```

Profiling:

Cluster 1: Lagu dengan banyak kemampuan menari dan energi, tetapi sedikit instrumental dan kenyaringan

Cluster 2: Lagu dengan banyak energi dan valensi, tetapi sedikit instrumental dan ucapan

Cluster 3: Lagu dengan banyak akustik dan instrumental, tetapi sedikit energi dan kenyaringan

Cluster 4: Lagu dengan banyak energi dan semangat, tetapi sedikit akustik dan instrumental

Cluster 5: Lagu dengan banyak instrumentalitas dan akustik, tetapi sedikit energi dan kenyaringan

Cluster 6: Lagu dengan banyak akustik dan kemampuan menari, tetapi sedikit bersemangat dan kenyaringan

Cluster 7: Lagu dengan banyak kemampuan menari dan ucapan, tetapi sedikit instrumentalitas dan valensi

Cluster 8: Lagu dengan banyak energi dan valensi, tetapi sedikit akustik dan instrumental


# Lagu Rekomendasi
Example Case 1
```{r}
popular_song %>% 
  filter(artist_name == "Linkin Park" & track_name == "Numb") %>% head(5)
```
Hasil dari artis "Linkin Park" dan nama lagu "Numb" kami memiliki 3 genre dengan cluster yang sama. Dari segi hasil clustering didapatkan hasil yang sama artinya 3 lagu tersebut berada pada cluster 3. Karena lagunya memiliki 3 genre, membuat Anda lebih memiliki pilihan untuk memilih genre yang ingin Anda dengar.

Misalnya, Anda memilih genre "Alternatif" dan musik apa yang selanjutnya akan disarankan?

```{r}
popular_song %>% 
  filter(cluster == 3 & ï..genre == "Alternative") %>% head(5)
```
You can filter song with “cluster 3” and genre “Alternative”. After that you can see 5 song with similar taste and composition.

Contoh Kasus 22 

Jika kamu sedang mendengarkan track “How Deep Is Your Love” dengan tempo lebih dari “100” tetapi belum tahu harus memilih musik selanjutnya setelah ini, model ini akan menunjukkan musik selanjutnya dengan komposisi dan rasa yang mirip.

```{r}
popular_song %>% 
  filter(track_name == "How Deep Is Your Love" & tempo > 100)
```


Hasil dari track_name “How Deep Is Your Love” dan tempo lebih dari 100, kami punya 3 genre dengan cluster yang sama. Dari segi hasil clustering didapatkan hasil yang sama artinya 2 lagu berada pada cluster 8. Karena lagunya memiliki 2 genre, membuat Anda lebih memiliki pilihan untuk memilih genre yang ingin Anda dengar.

Misalnya, Anda memilih genre "Pop" dan musik apa yang selanjutnya akan disarankan?

```{r}
popular_song %>% 
  filter(cluster == 8 & ï..genre == "Pop") %>% head() %>% as.data.frame()
```
Anda dapat memfilter lagu dengan "cluster 8" dan genre "Dance". Setelah itu Anda bisa melihat 115 lagu dengan rasa dan komposisi yang mirip.

# Kesimpulan
Dari analisis pembelajaran tanpa pengawasan di atas, dapat disimpulkan bahwa:

Reduksi dimensi dapat dilakukan dengan menggunakan dataset ini. Untuk melakukan reduksi dimensionalitas, kita dapat memilih PC dari total 8 PC sesuai dengan total informasi yang ingin kita simpan.

Kami dapat memisahkan data kami menjadi 8 cluster berdasarkan semua fitur numerik, dengan pengelompokan akurasi lebih dari 94,2%.




