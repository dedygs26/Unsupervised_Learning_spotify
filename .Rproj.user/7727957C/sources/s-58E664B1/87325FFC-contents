---
title: "Classification Analyze Quality Red-Wine with Naive Bayes, Decision Tree, and Random Forest"
author: "Dedy Gusnadi Sianipar"
date: "4/16/2021"
link-citation : true
output:
  html_document:
    theme: flatly
    higlight: zenburn
    toc: true
    toc_float:
      collapsed: true
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,out.width = "100%", echo = FALSE, fig.align = "center"}
knitr::include_graphics("5fce48f258fe06f370a48a9b_Red-Wine (1).jpg")
```

# BackGround

### About
This is data characteristic about Red-Wine quality, like chemical content and quality standard.

My purpose use this data is to analysis quality of Red wine based on chemical content.

### Description

Description Data:

-fixed acidity: most acids involved with wine

-volatile acidity: amount of acetic acid in wine

-citric acid: found in small quantities

-residual sugar: amount of sugar remaining after wine fermentation/production

-chlorides: amount of salt in the wine

-free sulfur dioxide: free forms of S02, prevents microbial growth and the oxidation of wine

-total sulfur dioxide: amount of free and bound forms of S02

-density: the density of water depending on the percent alcohol and sugar content

-pH: describes how acidic or basic a wine is on a scale 0-14 (very acidic: 0, very basic: 14); most wines are between 3-4 on the pH scale

-sulphates: an antimicrobial and antioxidant

-alcohol: the percent alcohol content of the wine

<p><a href = "https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009"> Kaggle </a></p>

# Set-Up
### Library
```{r,message=FALSE}
library(dplyr) # Wrangling Data
library(caret) # Confussion Matrix
library(FactoMineR) #
library(e1071)# Naive Bayes
library(ROCR) # ROC
library(randomForest) # Random Forest
library(partykit) # Decision Tree
library(rsample)
```

### Data
```{r}
red_wine <- read.csv("winequality-red.csv")
```

# Explanatory Data Analysis
```{r}
summary(red_wine)
```

We are going to build a predictive model to classify red wine quality, whereas the quality score of 7-10 is considered “Excellent”. Therefore, I subsetted the white wine data and removed type for a cleaner data analysis.

```{r}
unique(red_wine$quality)
```

### Check Missing Value
```{r}
anyNA(red_wine)
```
### Change Data Type
```{r}
red_wine <- red_wine %>% 
  mutate(quality=as.factor(ifelse(quality>6,"Excellent","Poor-Normal")))
red_wine
```

### Check Proportion Data Train
```{r}
prop.table(table(red_wine$quality))
```
You see an imbalance in the proportions of the data, so we will `downsample` to balance the proportions of the data


```{r}

set.seed(211)
wine_dsamp <- downSample(x= red_wine %>% select(-quality),
                        y=red_wine$quality,
                        yname = "quality")

```

```{r}
prop.table(table(wine_dsamp$quality))
```
```{r}
set.seed(417)

split <- initial_split(data = red_wine, prop = 0.8, strata = "quality")

train <- training(split)
test <- testing(split)

```

```{r}
prop.table(table(train$quality))
```

# Naive Bayes

### Naive Bayes Model

```{r}

# model building
naive <- naiveBayes(wine_dsamp %>% select(-quality), wine_dsamp$quality, laplace = 1)
# model fitting
naive_pred <- predict(naive, test, type = "class") # for the class prediction
```


### EValuation of Naive Bayes Model

```{r}
# result
confusionMatrix(naive_pred,test$quality,positive = "Excellent")
```

### Check Performace Model

#### ROC (Receiver Operating Curve)

ROC is a curve are plots correlation between True Positive Rate (Sensitivity or Recall) and False Positive Rate (Specificity). Good model ideally “High TP and Low FP”
```{r}

naive_prob <- predict(naive, newdata = test,type = "raw")
# membuat objeck prediction
wine_roc <- prediction(predictions = naive_prob[,1],# prob kelas positif
                       labels = as.numeric(test$quality =="Excellent"))

# performa dari object prediction
perf <- performance(prediction.obj = wine_roc,
                    measure = "tpr",
                    x.measure = "fpr")

plot(perf)
abline(0,1, lty = 2)
```
Based on plot, line make a curve arc (High True Positive and Low False Positive) its mean good model

#### AUC (Area Under ROC Curve)
AUC show large are under ROC curve, parameter AUC if value close to 1, model good.
```{r}
auc <- performance(prediction.obj = wine_roc, 
                   measure = "auc")
auc@y.values
```
Value AUC 0.8384732, close to 1 its means good model

### Interpretation

Accuracy : 0.6865 –> 68,65% model to correctly guess the target (Excellent / Poor-Normal).

Sensitivity (Recall) : 0.8140 –> 81.4% from all the positive actual data, capable proportion of model to guess right.

Specificity : 0.6667 –> 66,57% from all the negative actual data, capable proportion of model to guess right.

Pos Pred (Precision) : 0.2756 –> 27.56% from all the prediction result, capable model to correctly guess the positive class.

Based on Confussion Matrix model Naive Bayes, value Accuracy (68,65%) and (Recall 81.14% model). Its means Accuracy model can predict quality wine Excellent or Poor-Normal 68,65 % and model can predict quality wine Good is 80.1%.


# Decision Tree
### Model

```{r}
model_dt <- ctree(quality~.,red_wine)
```

### Prediction and Evaluation Model

#### Prediction And  Evaluation Using Data `Test`

```{r}
dtree_pred <- predict(model_dt, test, type = "response")
confusionMatrix(dtree_pred,reference = test$quality, positive = "Excellent")
```

#### Prediksi dan evaluasi model menggunakan data train
```{r}
pred_dt_train <- predict(model_dt, newdata = wine_dsamp, type = "response")
confusionMatrix(pred_dt_train, wine_dsamp$quality, positive = "Excellent")
```

#### summary prediction and evaluation
```{r}
model_dt_recap <- c("test", "wine_train_dsample")
Accuracy <- c(0.8746,0.8046)
Recall <- c(0.4186,0.4931)

tabelmodelrecap <- data.frame(model_dt_recap,Accuracy,Recall)

print(tabelmodelrecap)
```
Cause value Accuracy with data_test and data_train imbalance
(overfitting), model must to prunning to make right fitting.

#### Pruning

```{r}
model_dt_tun <- ctree(quality ~ ., wine_dsamp,
                               control = ctree_control(mincriterion = 0.5,
                                            minsplit = 35, #40
                                            minbucket = 20)) #12
```

```{r}
pred_dt_test_tun <- predict(model_dt_tun, newdata = test, type = "response")
confusionMatrix(pred_dt_test_tun, test$quality, positive = "Excellent")
```
```{r}
pred_dt_train_tun <- predict(model_dt_tun, newdata = wine_dsamp, type = "response")
confusionMatrix(pred_dt_train_tun, wine_dsamp$quality, positive = "Excellent")
```
#Summary Prediction and Evaluation
```{r}
model_dt_recap_prun <- c("wine.test", "wine_train_down")
Accuracy_prun <- c(0.8119,0.8046)
Recall_prun <- c(0.9535,0.9673)

tabelmodelrecap2 <- data.frame(model_dt_recap_prun,Accuracy_prun,Recall_prun)

print(tabelmodelrecap2)
```

# Create Plot Decision Tree
```{r,fig.height=10, fig.width=15}
#model_dt_tun
plot(model_dt_tun,type = "simple")
```
Nodes 1 is Root Nodes (Highest node in the tree structure, and has no parent)

Nodes 2,3,4,9,10,and 11 is Inner Nodes (Node of a tree that has child nodes)

Nodes 5,6,7,8,12,13,14,and 15 is Terminal Nodes (Node that does not have child nodes)

# random Forest
### K-Fold Cross Validation

Split data by [Math Processing Error] part, where each part is used to testing data.

Make model random forest using 5-fold cross validation and repeat process 3 times, after that save on RDS

```{r}

set.seed(417)

ctrl <- trainControl(method = "repeatedcv",
                     number = 5, # k-fold
                     repeats = 3) # repetisi

fb_forest <- train(quality ~ .,
                   data = wine_dsamp,
                   method = "rf", # random forest
                   trControl = ctrl)

saveRDS(fb_forest, "fb_forest_updates.RDS") # simpan model
```

### Model Random Forest Model
Read RDS

```{r}
forestt <- readRDS("fb_forest_updates.RDS")
varImp(forestt)
```
### Model Evaluation

```{r}
forestt$finalModel
```
oob error data sebesar 14.29 persen, its mean this model has 86,71 % of accuracy

### Check Importance Variable
```{r}
plot(varImp(forestt))
```
# Make Prediction adn Evaluation Model
Make prediction and check model evaluation with positive class “Good” using data_test
```{r}
pred_rfs <- predict(forestt, test,type = "raw")
confusionMatrix(pred_rfs,reference = test$quality,positive = "Excellent")
```
### Interpretation Random Forest

Accuracy : 0.8056 –> 80.56% model to correctly guess the target (Excellent/Poor-Normal).

-Sensitivity (Recall) : 1 –> 100% from all the positive actual data, capable proportion of model to guess right.

-Specificity : 0.7717 –> 77,17% from all the negative actual data, capable proportion of model to guess right.

-Pos Pred (Precision) : 0.4057 –> 40.57% from all the prediction result, capable model to correctly guess the positive class.

Based on Confussion Matrix model Random Forest, value Accuracy (80.56%) and (Recall 100% ). Its means Accuracy model can predict quality wine Excellent or Poor-Normal 78.1% and model can predict quality wine Good is 100%.

# Conculsion
```{r}
Model_Name <- c("Naive Bayes", "Decission Tree", "Random Forest")
Accuracy <- c(0.6865,0.7398,0.8056)
Recall <- c(0.8140,0.7907,1.000)
Specificity <- c(0.6667,0.7319,0.7717)
Precision <- c(0.2756,0.3148,0.4057)

modelrecapall <- data.frame(Model_Name,Accuracy,Recall,Specificity,Precision)

print(modelrecapall)
```

After make 3 model we get result Accuracy, Recall, Specificity, and Precision. In this case we will choose Random Forest Model, because model can predict quality wine `Excellent` and `Poor-Normal` with accuracy 80.8% and model can predict quality “Excellent” 100%. So we want all wine quality `Poor-Normal`not mix with all wine quality `Excellent`.
